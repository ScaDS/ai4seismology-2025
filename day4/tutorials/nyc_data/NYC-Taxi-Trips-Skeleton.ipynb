{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxi Trips (exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel installation\n",
    "\n",
    "- Run the following line (script) once, if the required kernel (big-data-dda-kernel) is not installed.\n",
    "- You need to install this kernel only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p ~/.local/share/jupyter/kernels/ai4seismology-bigdata\n",
    "cp /data/horse/ws/s4122485-ai4seismology_dev/thursday_bigdata/kernel.json ~/.local/share/jupyter/kernels/ai4seismology-bigdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important!!!\n",
    "Once the Kernel is installed, \n",
    "1. Reload the notebook (reload/refresh the web page)\n",
    "2. Select the kernel: Menu -> Kernel -> Change Kernel -> Select \"dda-kernel\"\n",
    "Always use this kernel for upcoming exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select ai4seismology-bigdata kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install --user --upgrade ipympl jupyter_leaflet leafmap ipyleaflet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restart the Jupyter Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To enable horizontal scrolling\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Initialisation of Spark cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: Skip if running on local machine\n",
    "# Import utilities required to run big data frameworks on ZIH HPC systems\n",
    "from big_data_utils.environment_utils import ClusterConfig\n",
    "from big_data_utils.cluster_utils import ClusterService\n",
    "from big_data_utils.utils import kill_java_processes_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Skip if running on local machine\n",
    "# Configure the cluster environment\n",
    "myconfig = ClusterConfig(fw_name=\"spark\")\n",
    "#myconfig.configure_env(conf_dest=\"./my-conf\", conf_template=\"/projects/p_scads_bigdatahpc/.template/spark\")\n",
    "myconfig.configure_env(conf_dest=\"./my-conf\",randomize_ports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the cluster service class\n",
    "mycluster = ClusterService(\"spark\")\n",
    "\n",
    "# Check which processes are running\n",
    "mycluster.check_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Skip if running on local machine\n",
    "# Start Spark standalone cluster\n",
    "mycluster.start_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: Skip if running on local machine\n",
    "# Check if the master and worker processes are started or not\n",
    "mycluster.check_status()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Download of NYC taxi trips and taxi zone file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the base directory in the following cell if you want to save data files in different directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "import zipfile\n",
    "\n",
    "base_directory = os.path.abspath(base_directory)\n",
    "os.environ[\"BASEDIRECTORY\"] = base_directory\n",
    "\n",
    "# Download yellow trip data\n",
    "data_directory = base_directory + \"/taxidata\"\n",
    "data_file = \"yellow_tripdata_2022-01.parquet\"\n",
    "data_path = data_directory + \"/\" + data_file\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "if not os.path.exists(data_path):\n",
    "    wget.download(\"https://d37ci6vzurychx.cloudfront.net/trip-data/\" + data_file, out = data_directory)   \n",
    "\n",
    "# Download zone data\n",
    "zone_directory = base_directory + \"/taxizonesdata\"\n",
    "if not os.path.isdir(zone_directory):\n",
    "    os.makedirs(zone_directory, exist_ok=True)\n",
    "\n",
    "zone_zipfile = \"taxi_zones.zip\"\n",
    "zone_zipfile_path = zone_directory + \"/\" + zone_zipfile\n",
    "if not os.path.exists(zone_zipfile_path):\n",
    "    wget.download(\"https://d37ci6vzurychx.cloudfront.net/misc/\" + zone_zipfile, out = zone_directory)\n",
    "    with zipfile.ZipFile(zone_zipfile_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(zone_directory)\n",
    "        zip_ref.close()\n",
    "    \n",
    "zone_lookup_file = \"taxi_zone_lookup.csv\"\n",
    "if not os.path.exists(zone_directory + \"/\" + zone_lookup_file):\n",
    "    wget.download(\"https://d37ci6vzurychx.cloudfront.net/misc/\" + zone_lookup_file, out = zone_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Initialisation of Spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "import os\n",
    "findspark.init(os.environ['SPARK_HOME'])\n",
    "print(os.environ['SPARK_HOME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(f\"spark://{myconfig.get_master_host()}:{myconfig.get_master_port()}\") \\\n",
    "    .appName(\"Python Spark Map Visualization of NYC taxi trips\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check running java processes\n",
    "mycluster.check_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = spark.read.parquet(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Grouping using groupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using groupBy\n",
    "trips.groupBy(\"VendorID\").count().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Exercise 1\n",
    "Count trips grouped by passengers.\n",
    "\n",
    "Are there unexpected values? How can they be interpreted? Find more information on https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trips. #add something here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Exercise 2\n",
    "Find the minimal distance for these groups. Are there unexpected values? How can they be interpreted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trips. #add something here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Exercise 3\n",
    "Remove all trip distances of 0.0 miles from the previous result. What do you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trips. #add something here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# SQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "sqlContext = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary view from the DataFrame\n",
    "trips.createOrReplaceTempView(\"trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a SQL query\n",
    "query = \"SELECT fare_amount FROM trips WHERE trip_distance>=5\"\n",
    "sqlContext.sql(query).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Exercise 4\n",
    "Rewrite the previous statement without SQL, but with a functional statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trips. # add something here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary statistics\n",
    "trips.describe().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Exercise 5\n",
    "Find the distance for tips larger than $5  - Formulate a SQL query and apply it on the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = # add something here\n",
    "sqlContext.sql(query).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Exercise 6\n",
    "Formulate a query to get total amount of trip for distances larger than 30 miles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = # add something here\n",
    "sqlContext.sql(query).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Exercise 7\n",
    "Create a box-and-whisker plot of the numerical columns. What do these say about the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in trips.dtypes:\n",
    "    name = column[0]\n",
    "    colType = column[1]\n",
    "    if colType != 'string' and colType != 'timestamp' and colType != 'timestamp_ntz':\n",
    "        columnQuantiles = trips. # add something here\n",
    "        print(\"{} quantiles: {}\".format(name,columnQuantiles))\n",
    "        stats = [{\n",
    "            \"whislo\": columnQuantiles # add something here\n",
    "            \"q1\": columnQuantiles # add something here\n",
    "            \"med\": columnQuantiles # add something here\n",
    "            \"q3\": columnQuantiles # add something here\n",
    "            \"whishi\": columnQuantiles # add something here\n",
    "        }]\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(5,5), sharey=True)\n",
    "        axes.bxp(bxpstats=stats, showfliers=False)\n",
    "        axes.grid(True)\n",
    "        axes.set_title(name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Exercise 8\n",
    "Provide an overview over the number of trips per week day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def barchart(dataRows, titleSuffix):\n",
    "    positions = list(reversed(range(len(dataRows))))\n",
    "    names = [str(item[titleSuffix]) + \" (\" + str(item['count']) + \")\" for item in dataRows]\n",
    "    values = [item['count'] for item in dataRows]\n",
    "    plt.grid()\n",
    "    plt.barh(positions,values,align=\"center\")\n",
    "    plt.yticks(positions,names)\n",
    "    plt.xlabel(\"Number of trips\")\n",
    "    plt.title(\"Distribution of trips per \" + titleSuffix)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "help(datetime.datetime.weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import IntegerType\n",
    "import calendar\n",
    "\n",
    "#udf stands for user defined function\n",
    "@udf \n",
    "def weekdayStr(d):\n",
    "    return calendar.day_name # add something here\n",
    "\n",
    "@udf(returnType=IntegerType())\n",
    "def weekday(d):\n",
    "    return d.weekday()\n",
    "\n",
    "#Replace function weekday with function weekdayStr if you want.\n",
    "weekdayRows = trips.select(weekday(trips.tpep_dropoff_datetime).alias(\"weekday\")). # add something here\n",
    "\n",
    "barchart(weekdayRows, \"weekday\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Exercise 9\n",
    "Provide an overview over the number of trips per hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@udf(returnType=IntegerType())\n",
    "def hour(d):\n",
    "    return d.hour\n",
    "\n",
    "hourRows = # add something here\n",
    "\n",
    "barchart(hourRows, \"hour\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Map Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import leafmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMap():\n",
    "    map_args={\n",
    "        \"google_map\":\"HYBRID\",\n",
    "        #center to New York at 41 degrees north and 74 degrees west ([lat, lon])\n",
    "        \"center\":[40.702557, -74.012318],\n",
    "        \"zoom\":12,\n",
    "        \"height\":\"450px\",\n",
    "        \"width\":\"800px\",\n",
    "        \"max_zoom\":\"20\"\n",
    "    }\n",
    "    return leafmap.Map(**map_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "getMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def taxizoneColorFunction(taxiZonesIntensity, maximum_intensity, taxizoneFeature):\n",
    "    taxizoneId = taxizoneFeature[\"properties\"][\"LocationID\"]\n",
    "    taxizoneIntensity = taxiZonesIntensity[taxizoneId] if taxizoneId in taxiZonesIntensity else 0\n",
    "    return {\n",
    "        \"color\": \"black\",\n",
    "        \"fillColor\": '#%02X0000' % (int(taxizoneIntensity*255/maximum_intensity))\n",
    "    }\n",
    "def getTaxiZoneStylingFunction(taxiZonesIntensity):\n",
    "    maximum_intensity = max(taxiZonesIntensity.values())\n",
    "    return lambda x: taxizoneColorFunction(taxiZonesIntensity, maximum_intensity, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxizonesFile = base_directory+\"/taxizonesdata/taxi_zones.shp\"\n",
    "\n",
    "def getZoneCenters():\n",
    "    zone_centers={}\n",
    "    my_geojson = leafmap.shp_to_geojson(taxizonesFile)\n",
    "    for feature in my_geojson[\"features\"]:\n",
    "        location = feature[\"properties\"][\"LocationID\"]\n",
    "        coordinates = feature[\"geometry\"][\"coordinates\"]\n",
    "        avg_lat = 0\n",
    "        avg_lon = 0\n",
    "        count = 0\n",
    "        for coordinate_list in coordinates:\n",
    "            for coordinate in coordinate_list:\n",
    "                if type(coordinate) == tuple and len(coordinate) == 2:\n",
    "                    avg_lat += coordinate[1]\n",
    "                    avg_lon += coordinate[0]\n",
    "                    count += 1\n",
    "                elif len(coordinate) > 2:\n",
    "                    for coord in coordinate:\n",
    "                        avg_lat += coord[1]\n",
    "                        avg_lon += coord[0]\n",
    "                        count += 1\n",
    "        \n",
    "        avg_lat = avg_lat/count\n",
    "        avg_lon = avg_lon/count\n",
    "        zone_centers[location]=[avg_lat, avg_lon]\n",
    "    return zone_centers\n",
    "\n",
    "zoneCenters = getZoneCenters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHeatCenters(taxizoneIntensityMap):\n",
    "    heat_data=[]\n",
    "    for key, value in zoneCenters.items():\n",
    "        location = key\n",
    "        (lat, lon) = value\n",
    "        taxizoneIntensity = taxizoneIntensityMap[location] if location in taxizoneIntensityMap else 0\n",
    "        heat_data.append([lat, lon, taxizoneIntensity])\n",
    "    return heat_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Exercise 10\n",
    "Get the number of trips which start/end in each zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickupData = trips. #add something here\n",
    "dropoffData = trips. #add something here\n",
    "grouped_by_pickup_location={row[\"PULocationID\"]:row[\"count\"] for row in pickupData}\n",
    "grouped_by_dropoff_location={row[\"DOLocationID\"]:row[\"count\"] for row in dropoffData}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = getMap()\n",
    "m.add_shp(in_shp=taxizonesFile,layer_name=\"taxizone\",style={},hover_style={}, style_callback=getTaxiZoneStylingFunction(grouped_by_pickup_location), fill_colors=None,\n",
    "              info_mode='on_hover')\n",
    "m.layer_opacity('taxizone', 0.9)\n",
    "m.add_heatmap(data=getHeatCenters(grouped_by_pickup_location), name='pickup_heat', radius=10)\n",
    "m.layer_opacity('pickup_heat', 0.9)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = getMap()\n",
    "m.add_shp(in_shp=taxizonesFile,layer_name=\"taxizone\",style={},hover_style={}, style_callback=getTaxiZoneStylingFunction(grouped_by_dropoff_location), fill_colors=None,\n",
    "              info_mode='on_hover')\n",
    "m.layer_opacity('taxizone', 0.9)\n",
    "m.add_heatmap(data=getHeatCenters(grouped_by_dropoff_location), name='dropoff_heat', radius=10)\n",
    "m.layer_opacity('dropoff_heat', 0.9)\n",
    "m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Exercise 11\n",
    "Collect the trips with the 10 highest tips. Be careful not to use trips with zones which indicate \"Unknown\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "zoneLookup = spark.read.csv(base_directory + \"/taxizonesdata/taxi_zone_lookup.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoneLookup.filter(zoneLookup.Borough == \"Unknown\").show()\n",
    "zoneLookup.filter(zoneLookup.Borough == \"N/A\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoneLookup.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(trips.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add something here to filter out Unknown values\n",
    "tripsWithHighestTips = temporary. # add something here to take the top 10 elements\n",
    "tripsWithHighestTips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geojson import FeatureCollection, Feature, LineString\n",
    "def to_lon_and_lat(latLonCoordinate):\n",
    "    return [latLonCoordinate[1],latLonCoordinate[0]]\n",
    "\n",
    "def trip_to_geojson(trip):\n",
    "    start_point = to_lon_and_lat(zoneCenters[trip[\"PULocationID\"]])\n",
    "    end_point = to_lon_and_lat(zoneCenters[trip[\"DOLocationID\"]])\n",
    "    props = {\n",
    "        \"starttime\":trip[\"tpep_pickup_datetime\"].isoformat(),\n",
    "        \"startzone\":trip[\"PULocationID\"],\n",
    "        \"endtime\":trip[\"tpep_dropoff_datetime\"].isoformat(),\n",
    "        \"endzone\":trip[\"DOLocationID\"],\n",
    "    }\n",
    "    return Feature(geometry=LineString([start_point, end_point]), properties=props)\n",
    "\n",
    "def tripList_to_geojson(tripList):\n",
    "    coll = FeatureCollection(list(map(lambda item: trip_to_geojson(item),tripList)))\n",
    "    return coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_geojson = tripList_to_geojson(tripsWithHighestTips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = getMap()\n",
    "m.add_shp(in_shp=taxizonesFile,layer_name=\"taxizone\")\n",
    "m.layer_opacity('taxizone', 0.9)\n",
    "m.add_geojson(in_geojson=trip_geojson,layer_name=\"connections\", style={\"color\":\"red\"})\n",
    "m.layer_opacity('connections', 1.0)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status of runnning java processes\n",
    "mycluster.check_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopping spark context\n",
    "sc.stop()\n",
    "mycluster.check_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycluster.stop_cluster()\n",
    "kill_java_processes_by_name(\"SparkSubmit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycluster.check_status()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4seismology-bigdata",
   "language": "python",
   "name": "ai4seismology-bigdata"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/plain",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
